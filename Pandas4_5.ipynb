{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0kTbDwpuKZwDipzE52d9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ekawaka/PYTHON-DATA-ANALYSIS/blob/main/Pandas4_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wind Statistics\n",
        "Introduction:\n",
        "The data have been modified to contain some missing values, identified by NaN.\n",
        "Using pandas should make this exercise easier, in particular for the bonus question.\n",
        "\n",
        "You should be able to perform all of these operations without using a for loop or other looping construct."
      ],
      "metadata": {
        "id": "3Sx5XeNv8It8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1. Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MvY3Wl9W8gU4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. The data in 'wind.data' has the following format:\n",
        "\"\"\"\n",
        "Yr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\n",
        "61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\n",
        "61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\n",
        "61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\n",
        "\"\"\"\n",
        "\n",
        "# The first three columns are year, month and day. The remaining 12 columns are average windspeeds in knots at 12 locations in Ireland on that day."
      ],
      "metadata": {
        "id": "-wRRJw1f8Smf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2f1d12f2-ee69-4d22-e199-02daaf295672"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nYr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\\n61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\\n61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\\n61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2. Import the dataset from this address\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data')\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td5Eg26g8tQz",
        "outputId": "1ab9d18c-0ac1-41af-9c45-0f074549c357"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Yr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\n",
            "0  61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 1...                              \n",
            "1  61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 1...                              \n",
            "2  61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 1...                              \n",
            "3  61  1  4 10.58  6.63 11.75  4.58  4.54  2.88  ...                              \n",
            "4  61  1  5 13.33 13.25 11.42  6.17 10.71  8.21 1...                              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3. Assign it to a variable called data and replace the first 3 columns by a proper datetime index.\n",
        "\n",
        "# Read the data and parse the first 3 columns as a datetime index\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data')\n",
        "\n",
        "parse_dates=[[0, 1, 2]]\n",
        "\n",
        "# Concatenate the Year, Month, and Day columns into a single datetime column\n",
        "data['Date'] = pd.to_datetime(data[['Yr', 'Mo', 'Dy']].astype(str).agg('-'.join, axis=1))\n",
        "\n",
        "# Set the new datetime column as the index and drop the original columns\n",
        "data.set_index('Date', inplace=True)\n",
        "data.drop(columns=['Yr', 'Mo', 'Dy'], inplace=True)\n",
        "\n",
        "# Display the first few rows of the updated DataFrame\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "s5ClsN469Qd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "20fa04ab-e29d-4db8-ddb9-23ca0f2be1f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['Yr', 'Mo', 'Dy'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1622134d45d7>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Concatenate the Year, Month, and Day columns into a single datetime column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Yr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Set the new datetime column as the index and drop the original columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5937\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5938\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Yr', 'Mo', 'Dy'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7TN37Yf0_el",
        "outputId": "ce0c20ff-d8ac-44ae-a63b-ae39720c5d29"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Yr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\n",
            "0  61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 1...                              \n",
            "1  61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 1...                              \n",
            "2  61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 1...                              \n",
            "3  61  1  4 10.58  6.63 11.75  4.58  4.54  2.88  ...                              \n",
            "4  61  1  5 13.33 13.25 11.42  6.17 10.71  8.21 1...                              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4. Year 2061? Do we really have data from this year? Create a function to fix it and apply it.\n",
        "\n",
        "def fix_year(date_column, threshold_year=2000):\n",
        "    \"\"\"\n",
        "    Adjusts the year of dates if it's above a specified threshold year.\n",
        "\n",
        "    Parameters:\n",
        "        date_column (pandas.Series): Series containing datetime values.\n",
        "        threshold_year (int): The threshold year. Dates with a year greater than this will be adjusted.\n",
        "\n",
        "    Returns:\n",
        "        pandas.Series: Series with adjusted datetime values.\n",
        "    \"\"\"\n",
        "    # Adjust the year if it's greater than the threshold year\n",
        "    adjusted_dates = date_column.apply(lambda x: x - pd.DateOffset(years=100) if x.year > threshold_year else x)\n",
        "    return adjusted_dates\n",
        "\n",
        "# Read the data and parse the first 3 columns as a datetime index\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data',\n",
        "                   parse_dates=[[0, 1, 2]])\n",
        "\n",
        "# Apply the function to fix the dates\n",
        "data['Yr_Mo_Dy'] = fix_year(data['Yr_Mo_Dy'], threshold_year=2000)\n",
        "\n",
        "# Set the adjusted datetime column as the index\n",
        "data.set_index('Yr_Mo_Dy', inplace=True)\n",
        "\n",
        "# Display the first few rows of the updated DataFrame\n",
        "print(data.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "Ok1gWTUd-xo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5. Set the right dates as the index. Pay attention at the data type, it should be datetime64[ns].\n",
        "\n",
        "def fix_year(date_column, threshold_year=2000):"
      ],
      "metadata": {
        "id": "iR37P0iW_OUz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "a9b6a3ee-a012-40f6-bce4-3c83be61f9c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-22-31cf6f8b3de1>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-31cf6f8b3de1>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    def fix_year(date_column, threshold_year=2000):\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6. Compute how many values are missing for each location over the entire record.\n",
        "#They should be ignored in all calculations below."
      ],
      "metadata": {
        "id": "mGO_UJxR_Rcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7. Compute how many non-missing values there are in total."
      ],
      "metadata": {
        "id": "-wn2Qx57_WA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8. Calculate the mean windspeeds of the windspeeds over all the locations and all the times.\n",
        "# A single number for the entire dataset."
      ],
      "metadata": {
        "id": "vhHG18gs_Zhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9. Create a DataFrame called loc_stats and calculate the min, max and mean windspeeds and standard deviations of the windspeeds at each location over all the days\n",
        "# A different set of numbers for each location."
      ],
      "metadata": {
        "id": "g-zeqT--_fK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10. Create a DataFrame called day_stats and calculate the min, max and mean windspeed and standard deviations of the windspeeds across all the locations at each day.\n",
        "# A different set of numbers for each day."
      ],
      "metadata": {
        "id": "VcgBZY0z_jPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 11. Find the average windspeed in January for each location.\n",
        "# Treat January 1961 and January 1962 both as January."
      ],
      "metadata": {
        "id": "4-24yVC7_qX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12. Downsample the record to a yearly frequency for each location."
      ],
      "metadata": {
        "id": "wv5Mf9T-_v-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 13. Downsample the record to a monthly frequency for each location.\n"
      ],
      "metadata": {
        "id": "ZrfLC1_c_zRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14. Downsample the record to a weekly frequency for each location."
      ],
      "metadata": {
        "id": "tkRAeHLY_3wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 15. Calculate the min, max and mean windspeeds and standard deviations of the windspeeds across all locations for each week (assume that the first week starts on January 2 1961) for the first 52 weeks."
      ],
      "metadata": {
        "id": "-Dy9Svq3_6Hw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}